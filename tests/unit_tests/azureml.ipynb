{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d639693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.azureml_endpoint import AzureMLModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8890dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi! How are you doing today? A lot better than last time. We won today and we will do better next time.\" -The leader of the group\\n\\n- \"You have been defeated. Great! We\\'ll be able to go next'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_llm = AzureMLModel(\n",
    "    endpoint_url=os.getenv(\"ENDPOINT_URL\"),\n",
    "    endpoint_api_key=os.getenv(\"ENDPOINT_API_KEY\"),\n",
    "    deployment_name=\"matthew-gpt-2\",\n",
    "    model_kwargs={\"temperature\": 0.9, \"top_p\": 0.3},\n",
    "    catalog_type=\"open_source\"\n",
    ")\n",
    "resp = azure_llm(\"Hi! How are you doing today?\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67074e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=\"Tell me a funny joke. What if I told you a funny joke?\\n\\nI'll start with a joke. There's no chance to finish it.\\n\\nWhat if we told you something really hard that's happening right now?\\n\\n\", generation_info=None)], [Generation(text=\"Tell me a sad poem? In the old days, there were no computers to worry about, no YouTube to check. I'd just write down whatever emotions I was feeling at the time. That's what my family and I were up to back then\", generation_info=None)], [Generation(text='Tell me a funny joke if, as a Canadian, I\\'m not allowed to say it and get punched.\"', generation_info=None)], [Generation(text='Tell me a sad poem...\" or something like \"I have not met him because you have all been so good to me/you are the only one who has shown me any kindness/You are so sweet and kind/and gentle like your sister /', generation_info=None)], [Generation(text=\"Tell me a funny joke. Like, in the middle of a question about how I'm going to make my fortune.\\n\\nAnd to answer: I do not know where our money goes. When the tax bill was filed I said that I didn\", generation_info=None)], [Generation(text=\"Tell me a sad poem. Have what befits you. In all your beauty and all your shame. Tell me a sad story and show me how it touches you. In all those moments when life is most beautiful, with all that's behind you\", generation_info=None)], [Generation(text='Tell me a funny joke, because we\\'re going to take a break.\"\\n\\n\"I have to go to the bathroom for a sec, so I\\'ll bring you another,\" I said with some amusement.\\n\\n\"I didn\\'t mean to', generation_info=None)], [Generation(text='Tell me a sad poem?\" When people do, say the first part of the second section. Then say the first part of the third section. Say it with a soft, quiet voice. You can also say it slowly.\\n\\nIn the third', generation_info=None)], [Generation(text='Tell me a funny joke or two. That\\'ll show me.\"\\n\\nDoyle also wrote about his past relationship with Tom Hanks and his relationship with his mother (the one he never had), as well as his current romance with his fianc', generation_info=None)], [Generation(text='Tell me a sad poem about the loss of that beloved friend that means the most to you.\"\\n\\n\"I will try.\"\\n\\n\"I will also try. There will come a time, you will think back to that day and you will', generation_info=None)], [Generation(text='Tell me a funny joke,\" she asks. \"How many of you do that, not by accident, as a joke to yourself or to someone you know, but as a joke to somebody else? But it\\'s so hard to do that.\"\\n', generation_info=None)], [Generation(text='Tell me a sad poem about someone that you like. The words are chosen by you and you must share a feeling with me that is important to you. I am going to tell you about a certain person who is a great friend and who you love', generation_info=None)], [Generation(text='Tell me a funny joke. I know it\\'s going to be hard for me to be funny about the situation.\"', generation_info=None)], [Generation(text='Tell me a sad poem about how it wasn\\'t you.\"\\n\\n\"A little girl on a porch\\n\\nWith a cat,\\n\\nCaught in a sunbeam\\n\\nAs that cat ran away\\n\\nHanging on the door.', generation_info=None)], [Generation(text='Tell me a funny joke. [Pause] Good, now I get it. [More jokes and giggles] [Moans of pleasure] Yummy! (Moans) Yeah.. you like that? Feeling those muscles contract around you, my', generation_info=None)], [Generation(text='Tell me a sad poem, please,\" and it\\'s \"What Could Have Been,\" by Leonard Cohen. But no one has done that yet, and it\\'s a very sad poem. But I\\'m really happy that people are starting to get interested.', generation_info=None)], [Generation(text='Tell me a funny joke,\" he says. \"Which one of the guys is the weird one? I don\\'t know that.\"\\n\\nAdvertisement\\n\\n\\nThen he moves past jokes about the U.S. military in Afghanistan, or the U.', generation_info=None)], [Generation(text='Tell me a sad poem of one\\'s own to read when people talk to you\".\\n\\n\"But, please don\\'t write it again in a journal. It is a lot of writing. And, while I\\'m here, please, don\\'t', generation_info=None)], [Generation(text='Tell me a funny joke to try and impress the lady\" or something.\\n\\nA bit later.\\n\\n\"But what about you guys?\" She called out, and I did a double take, realizing that she was calling me a nerd,', generation_info=None)], [Generation(text='Tell me a sad poem about your life... about you. Let me hear it, I think I can understand how you love this life. It is beautiful, but you know it. This is not just for the money, the beauty of it is', generation_info=None)]], llm_output=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_llm.generate([\"Tell me a funny joke\", \"Tell me a sad poem\"] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f386d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='Create a program that determines if an integer is prime.\\n\\nCreate a program that generates some prime numbers and tries to get a prime number that is less than itself.\\n\\nCreate a program that generates some primes and tries to find the highest', generation_info=None)], [Generation(text='Why is the sky blue?\\nThe sky is blue when looking towards the sun at low angles of incidence and high angles of incidence. This is an example in Cartesian coordinates.\\n\\n1) What is the angular width of the blue band?', generation_info=None)], [Generation(text='Where is the earth located in our orbit: How close is it to us?What happens to the earth during times of intense gravitational stress: How does it react?\\n\\nWhat is the atmosphere of the earth made up of?\\n\\nWhat is', generation_info=None)]], llm_output=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_llm = AzureMLModel(\n",
    "    endpoint_url=os.getenv(\"HG_ENDPOINT_URL\"),\n",
    "    endpoint_api_key=os.getenv(\"HG_ENDPOINT_API_KEY\"),\n",
    "    deployment_name=\"matthew-salesfoce-codegen\",\n",
    "    catalog_type=\"hugging_face\"\n",
    ")\n",
    "hg_llm.generate([\"Create a program that determines if an integer is prime.\", \"Why is the sky blue?\", \"Where is the earth located\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0dbe95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every Word\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: light\n",
      "Antonym: dark\n",
      "\n",
      "Word: fast\n",
      "Antonym: slow\n",
      "\n",
      "Word: high\n",
      "Antonym: low\n",
      "\n",
      "Word: windy\n",
      "Antonym: calm\n",
      "\n",
      "Word: energetic\n",
      "Antonym: lethargic\n",
      "\n",
      "Word: trash\n",
      "Antonym: urn\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "    {\"word\": \"light\", \"antonym\": \"dark\"},\n",
    "    {\"word\": \"fast\", \"antonym\": \"slow\"},\n",
    "    {\"word\": \"high\", \"antonym\": \"low\"},\n",
    "    {\"word\": \"windy\", \"antonym\": \"calm\"},\n",
    "    {\"word\": \"energetic\", \"antonym\": \"lethargic\"}\n",
    "]\n",
    "formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=formatter_template\n",
    ")\n",
    "\n",
    "few_shot_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every Word\\n\",\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "few_shot_result = azure_llm(few_shot_template.format(input=\"trash\"))\n",
    "print(few_shot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99205e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse output: Question: Who lived longer, Muhammad Ali or Alan Turing?\nAre follow up questions needed here: Yes.\nFollow up: How old was Muhammad Ali when he died?\nIntermediate answer: Muhammad Ali was 74 years old when he died.\nFollow up: How old was Alan Turing when he died?\nIntermediate answer: Alan Turing was 41 years old when he died.\nSo the final answer is: Muhammad Ali\n\nQuestion: When was the founder of craigslist born?\nAre follow up questions needed here: Yes.\nFollow up: Who was the founder of craigslist?\nIntermediate answer: Craigslist was founded by Craig Newmark.\nFollow up: When was Craig Newmark born?\nIntermediate answer: Craig Newmark was born on December 6, 1952.\nSo the final answer is: December 6, 1952\n\nQuestion: Who was the maternal grandfather of George Washington?\nAre follow up questions needed here: Yes.\nFollow up: Who was the mother of George Washington?\nIntermediate answer: The mother of George Washington was Mary Ball Washington.\nFollow up: Who was the father of Mary Ball Washington?\nIntermediate answer: The father of Mary Ball Washington was Joseph Ball.\nSo the final answer is: Joseph Ball\n\nQuestion: Are both the directors of Jaws and Casino Royale from the same country?\nAre follow up questions needed here: Yes.\nFollow up: Who is the director of Jaws?\nIntermediate answer: The director of Jaws is Steven Spielberg.\nFollow up: Where is Steven Spielberg from?\nIntermediate answer: The United States.\nFollow up: Who is the director of Casino Royale?\nIntermediate answer: The director of Casino Royale is Martin Campbell.\nFollow up: Where is Martin Campbell from?\nIntermediate answer: New Zealand.\nSo the final answer is: No\n\nQuestion: What is the hometown of the reigning men's U.S. Open champion?\nAre followup questions needed here: Yes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m      7\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     Tool(\n\u001b[0;32m      9\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntermediate Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     14\u001b[0m self_ask_with_search \u001b[38;5;241m=\u001b[39m initialize_agent(tools, hg_llm, agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mSELF_ASK_WITH_SEARCH, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mself_ask_with_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the hometown of the reigning men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms U.S. Open champion?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\agents\\agent.py:953\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 953\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m    962\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m    963\u001b[0m         )\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\agents\\agent.py:773\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    771\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 773\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    774\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\agents\\agent.py:762\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \n\u001b[0;32m    758\u001b[0m \u001b[38;5;124;03mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 762\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m    763\u001b[0m         intermediate_steps,\n\u001b[0;32m    764\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    765\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m    766\u001b[0m     )\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\agents\\agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    443\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Developer\\langchain\\langchain\\agents\\self_ask_with_search\\output_parser.py:15\u001b[0m, in \u001b[0;36mSelfAskOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m([follow \u001b[38;5;129;01min\u001b[39;00m last_line \u001b[38;5;28;01mfor\u001b[39;00m follow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollowups]):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinish_string \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m last_line:\n\u001b[1;32m---> 15\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AgentFinish({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_line[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinish_string) :]}, text)\n\u001b[0;32m     18\u001b[0m after_colon \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse output: Question: Who lived longer, Muhammad Ali or Alan Turing?\nAre follow up questions needed here: Yes.\nFollow up: How old was Muhammad Ali when he died?\nIntermediate answer: Muhammad Ali was 74 years old when he died.\nFollow up: How old was Alan Turing when he died?\nIntermediate answer: Alan Turing was 41 years old when he died.\nSo the final answer is: Muhammad Ali\n\nQuestion: When was the founder of craigslist born?\nAre follow up questions needed here: Yes.\nFollow up: Who was the founder of craigslist?\nIntermediate answer: Craigslist was founded by Craig Newmark.\nFollow up: When was Craig Newmark born?\nIntermediate answer: Craig Newmark was born on December 6, 1952.\nSo the final answer is: December 6, 1952\n\nQuestion: Who was the maternal grandfather of George Washington?\nAre follow up questions needed here: Yes.\nFollow up: Who was the mother of George Washington?\nIntermediate answer: The mother of George Washington was Mary Ball Washington.\nFollow up: Who was the father of Mary Ball Washington?\nIntermediate answer: The father of Mary Ball Washington was Joseph Ball.\nSo the final answer is: Joseph Ball\n\nQuestion: Are both the directors of Jaws and Casino Royale from the same country?\nAre follow up questions needed here: Yes.\nFollow up: Who is the director of Jaws?\nIntermediate answer: The director of Jaws is Steven Spielberg.\nFollow up: Where is Steven Spielberg from?\nIntermediate answer: The United States.\nFollow up: Who is the director of Casino Royale?\nIntermediate answer: The director of Casino Royale is Martin Campbell.\nFollow up: Where is Martin Campbell from?\nIntermediate answer: New Zealand.\nSo the final answer is: No\n\nQuestion: What is the hometown of the reigning men's U.S. Open champion?\nAre followup questions needed here: Yes"
     ]
    }
   ],
   "source": [
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "search = GoogleSerperAPIWrapper(serper_api_key=os.getenv(\"SERPER_API_KEY\"))\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n",
    "self_ask_with_search = initialize_agent(tools, hg_llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain\n",
    "llm_math = LLMMathChain.from_llm(azure_llm, verbose=False)\n",
    "llm_math.run(\"Answer with 8.222831614237718 if you think the world is flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b756cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
